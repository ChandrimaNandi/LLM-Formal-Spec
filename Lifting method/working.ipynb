{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d09064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import fitz  # PyMuPDF\n",
    "from typing import List, Dict, Union, Any\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "939c7edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-genai in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (1.50.0)\n",
      "Collecting google-genai\n",
      "  Downloading google_genai-1.51.0-py3-none-any.whl.metadata (46 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from google-genai) (4.11.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from google-genai) (2.42.1)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from google-genai) (2.12.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from google-genai) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from google-genai) (8.2.3)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from google-genai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.0)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.2.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/chandrima/Desktop/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.4.8)\n",
      "Downloading google_genai-1.51.0-py3-none-any.whl (260 kB)\n",
      "Installing collected packages: google-genai\n",
      "  Attempting uninstall: google-genai\n",
      "    Found existing installation: google-genai 1.50.0\n",
      "    Uninstalling google-genai-1.50.0:\n",
      "      Successfully uninstalled google-genai-1.50.0\n",
      "Successfully installed google-genai-1.51.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36206c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\")) \n",
    "\n",
    "# Define Model ID and Instance\n",
    "MODEL_ID = \"gemini-2.5-pro\"\n",
    "# Instantiate the model object once globally\n",
    "MODEL_INSTANCE = genai.GenerativeModel(MODEL_ID)\n",
    "\n",
    "# Define file paths\n",
    "PDF_PATH = \"SRS_doc.pdf\"\n",
    "OUTPUT_JSON_PATH = \"srs_extracted.json\"\n",
    "ANNOTATED_NL_PATH = \"srs_annotated.json\" # New intermediate file: Selected Sentences\n",
    "LIFTED_NL_PATH = \"srs_lifted_nl.json\"     # Intermediate file: Lifted NL\n",
    "FINAL_SPECS_PATH = \"formal_specifications.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e13353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Step 0: SRS Text Extraction (Unchanged) ---\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str, output_json_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts text from a real PDF file page by page and ensures the output JSON file \n",
    "    is created before returning the data.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"1. Starting text extraction from {pdf_path}...\")\n",
    "    data = {\"sections\": []} # Initialize data structure\n",
    "\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"ERROR: PDF file not found at {pdf_path}. Returning empty data structure.\")\n",
    "        # Write failure state to file\n",
    "        with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "        return data\n",
    "\n",
    "    # --- ACTUAL EXTRACTION LOGIC ---\n",
    "    try:\n",
    "        text_sections = []\n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            for i, page in enumerate(doc):\n",
    "                text = page.get_text(\"text\")\n",
    "                sentences = [s.strip() for s in text.split(\". \") if s.strip()]\n",
    "                text_sections.append({\n",
    "                    \"id\": f\"page_{i+1}\",\n",
    "                    \"sentences\": sentences\n",
    "                })\n",
    "        data[\"sections\"] = text_sections\n",
    "        print(f\"     Extracted text successfully from {len(data['sections'])} pages.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   Fatal Error during PDF extraction: {e}. Returning empty data structure.\")\n",
    "        data[\"sections\"] = []\n",
    "\n",
    "    # --- GUARANTEE: Write the data to the JSON file before returning ---\n",
    "    with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"    Final extracted data written to {output_json_path}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a73386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Running Step 0: Extraction ---\n",
      "1. Starting text extraction from SRS_doc.pdf...\n",
      "     Extracted text successfully from 37 pages.\n",
      "    Final extracted data written to srs_extracted.json\n"
     ]
    }
   ],
   "source": [
    "# Assuming global variables like PDF_PATH and OUTPUT_JSON_PATH are defined.\n",
    "print(\"--- 1. Running Step 0: Extraction ---\")\n",
    "extracted_data = extract_text_from_pdf(PDF_PATH, OUTPUT_JSON_PATH)\n",
    "\n",
    "if not extracted_data[\"sections\"]:\n",
    "    print(\"\\nExtraction failed. Cannot continue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATION_SCHEMA = { # Schema retained but used only for prompt instruction\n",
    "    \"type\": \"object\", \n",
    "    \"properties\": {\n",
    "        \"requirements\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"section_id\": {\"type\": \"string\"},\n",
    "                    \"sentence_text\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"section_id\", \"sentence_text\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"requirements\"]\n",
    "}\n",
    "\n",
    "# --- 2. Step 1: Annotation/Selection (FIXED API CALL with Sleep and Robust Parsing) ---\n",
    "\n",
    "# ANNOTATION_SCHEMA is assumed defined (retained for context)\n",
    "\n",
    "def step_1_annotate_selection(input_json: dict, model_instance: genai.GenerativeModel) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Step 1: Identifies and extracts actionable requirements from the full SRS text,\n",
    "    implementing a retry loop for rate limit errors and robust JSON parsing.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Step 1: Annotation/Selection using {MODEL_ID} ---\")\n",
    "    \n",
    "    srs_text_summary = json.dumps(input_json, indent=2)\n",
    "    MAX_RETRIES = 3 # Safety limit for retries\n",
    "    \n",
    "    SYSTEM_PROMPT = f\"\"\"\n",
    "    You are an expert in software engineering, analyzing an SRS document.\n",
    "    Your task is to identify and extract ONLY the sentences that represent \n",
    "    actionable system requirements (e.g., state transitions, system constraints, \n",
    "    user actions, or \"must/shall\" statements). Ignore introductory, descriptive, \n",
    "    or explanatory text.\n",
    "    \n",
    "    You MUST output the result in a clean JSON format strictly adhering to this structure:\n",
    "    {json.dumps(ANNOTATION_SCHEMA, indent=2)}\n",
    "    \"\"\"\n",
    "\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            print(f\"   -> Running annotation API call (Attempt {attempt} of {MAX_RETRIES})...\")\n",
    "            \n",
    "            response = model_instance.generate_content(\n",
    "                SYSTEM_PROMPT + \"\\n\\nJSON input:\\n\" + srs_text_summary\n",
    "            )\n",
    "\n",
    "            # 1. Robust JSON Parsing (Strip markdown and extra text)\n",
    "            raw_text = response.text.strip()\n",
    "            if raw_text.startswith(\"```\"):\n",
    "                raw_text = raw_text.strip(\"```json\").strip(\"```\").strip()\n",
    "\n",
    "            annotated_data = json.loads(raw_text)\n",
    "            \n",
    "            # 2. Key Error Fix: Use .get() or check for key existence\n",
    "            # This handles cases where the model returns valid JSON but misses the 'requirements' key.\n",
    "            if 'requirements' not in annotated_data:\n",
    "                raise KeyError(f\"JSON lacks 'requirements' key. Raw output: {raw_text[:100]}...\")\n",
    "\n",
    "            # Success: Process and return\n",
    "            selected_requirements = [\n",
    "                {\"Source_NL\": req[\"sentence_text\"], \"section_id\": req[\"section_id\"]}\n",
    "                for req in annotated_data[\"requirements\"] \n",
    "            ]\n",
    "            \n",
    "            with open(ANNOTATED_NL_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(selected_requirements, f, indent=2, ensure_ascii=False)\n",
    "                \n",
    "            print(f\"     Identified {len(selected_requirements)} actionable requirements.\")\n",
    "            print(f\"     Annotated requirements saved to {ANNOTATED_NL_PATH}\")\n",
    "            return selected_requirements\n",
    "\n",
    "        except Exception as e:\n",
    "            error_message = str(e)\n",
    "            \n",
    "            # --- FIX 1: Increase Sleep Time ---\n",
    "            if \"429\" in error_message and attempt < MAX_RETRIES:\n",
    "                # Use 75 seconds for a safe buffer against the strict 60s sliding window\n",
    "                print(f\"     Rate Limit Hit! Sleeping for 75 seconds before retrying...\")\n",
    "                time.sleep(75) \n",
    "            elif attempt < MAX_RETRIES:\n",
    "                # Wait 5 seconds for generic parsing errors (like JSONDecodeError) before retrying\n",
    "                print(f\"     Parsing/Structural Error: {error_message}. Retrying in 5 seconds...\")\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                # Catastrophic failure or max retries exceeded\n",
    "                print(f\"   Final Error during Annotation/Selection (Attempt {attempt}): {error_message}\")\n",
    "                return []\n",
    "    \n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba495acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. Running Step 1: Annotation/Selection ---\n",
      "\n",
      "--- Step 1: Annotation/Selection using gemini-2.5-pro ---\n",
      "   -> Running annotation API call (Attempt 1 of 3)...\n",
      "     Identified 93 actionable requirements.\n",
      "     Annotated requirements saved to srs_annotated.json\n"
     ]
    }
   ],
   "source": [
    "# Assuming MODEL_INSTANCE is defined globally.\n",
    "print(\"\\n--- 2. Running Step 1: Annotation/Selection ---\")\n",
    "selected_requirements = step_1_annotate_selection(extracted_data, MODEL_INSTANCE)\n",
    "\n",
    "if not selected_requirements:\n",
    "    print(\"\\nAnnotation failed. Cannot continue.\")\n",
    "\n",
    "# You can now inspect 'srs_annotated.json' or the 'selected_requirements' list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf7f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Step 2: Lifting (Batched API Call - FINAL FIX) ---\n",
    "\n",
    "LIFTING_SCHEMA = { \n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"Source_NL\": {\"type\": \"string\", \"description\": \"The original source sentence.\"},\n",
    "            \"Lifted_NL\": {\"type\": \"string\", \"description\": \"The structured, intermediate \"\n",
    "            \"'Lifted Natural Language' statement.\"}\n",
    "        },\n",
    "        \"required\": [\"Source_NL\", \"Lifted_NL\"]\n",
    "    }\n",
    "}\n",
    "BATCH_SIZE = 50 # Process 50 requirements per API call\n",
    "MAX_API_RETRIES = 2 # Max retries for a single batch request\n",
    "\n",
    "def step_2_perform_lifting(selected_requirements: List[Dict], model_instance: genai.GenerativeModel) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Step 2: Natural Language (NL) to Lifted NL (Lifting).\n",
    "    Implements a robust retry mechanism for rate limit errors within the batch loop.\n",
    "    \"\"\"\n",
    "    all_lifted_results = []\n",
    "    num_requests = 0\n",
    "    \n",
    "    print(f\"\\n--- Step 2: NL to Lifted NL (Lifting) using {MODEL_ID} ---\")\n",
    "    \n",
    "    # We keep the 60s initial wait to clear the quota from Step 1\n",
    "    print(f\"Waiting 60 seconds to ensure quota reset from previous API call (Step 1)...\")\n",
    "    time.sleep(60)\n",
    "    \n",
    "    # LIFTING_PROMPT is assumed defined globally.\n",
    "    \n",
    "    for i in range(0, len(selected_requirements), BATCH_SIZE):\n",
    "        batch = selected_requirements[i:i + BATCH_SIZE]\n",
    "        original_map = {req['Source_NL']: req for req in batch}\n",
    "        batch_nl = list(original_map.keys())\n",
    "        \n",
    "        print(f\"   Lifting Batch {num_requests + 1} ({len(batch)} items)...\")\n",
    "\n",
    "        # --- FIX: DEFINE 'contents' HERE (Inside batch loop, Outside retry loop) ---\n",
    "        contents = [\n",
    "            # FIX: Serialize LIFTING_SCHEMA dictionary to a string\n",
    "            {\"role\": \"user\", \"parts\": [{\"text\": json.dumps(LIFTING_SCHEMA)}]}, \n",
    "            \n",
    "            # Few-shot example \n",
    "            {\"role\": \"user\", \"parts\": [{\"text\": \"The manager must verify the plumber after registration if their status is unverified.\"}]},\n",
    "            {\"role\": \"model\", \"parts\": [{\"text\": json.dumps([{\"Source_NL\": \"The manager must verify the plumber after registration if their status is unverified.\", \n",
    "            \"Lifted_NL\": \"always (manager attempts to verify plumber p AND p's status is unverified) implies (p's status becomes active)\"}])}]},\n",
    "            \n",
    "            # Current Batch Query\n",
    "            {\"role\": \"user\", \"parts\": [{\"text\": \"Translate the following NL sentences:\\n\" + \"\\n\".join(f\"- {s}\" for s in batch_nl)}]}\n",
    "        ]\n",
    "        # --- END FIX ---\n",
    "\n",
    "        # --- NEW RETRY LOOP FOR API CALL ---\n",
    "        batch_processed_successfully = False\n",
    "        \n",
    "        for attempt in range(1, MAX_API_RETRIES + 1):\n",
    "            try:\n",
    "                # API call now safely uses the defined 'contents' variable\n",
    "                response = model_instance.generate_content(contents=contents)\n",
    "                num_requests += 1\n",
    "                batch_processed_successfully = True\n",
    "                \n",
    "                # If successful, break the retry loop and proceed to process results\n",
    "                break \n",
    "\n",
    "            except Exception as e:\n",
    "                error_message = str(e)\n",
    "                \n",
    "                if \"429\" in error_message and attempt < MAX_API_RETRIES:\n",
    "                    # FIX: Wait longer than the 48.4s suggested delay to ensure reset\n",
    "                    print(f\" Rate Limit Hit on Attempt {attempt}. Sleeping for 75 seconds before retrying...\")\n",
    "                    time.sleep(75) \n",
    "                else:\n",
    "                    # Log the final error if retries are exhausted or it's not a 429 error\n",
    "                    print(f\"     Final Error during Lifting Batch {num_requests}: {error_message}\")\n",
    "                    break\n",
    "        # --- END RETRY LOOP ---\n",
    "\n",
    "        # Process results ONLY if the API call was successful\n",
    "        if batch_processed_successfully:\n",
    "            try:\n",
    "                raw_text = response.text.strip()\n",
    "                if raw_text.startswith(\"```\"):\n",
    "                    raw_text = raw_text.strip(\"```json\").strip(\"```\").strip()\n",
    "\n",
    "                batch_results = json.loads(raw_text)\n",
    "                \n",
    "                # (Robust results processing logic remains the same)\n",
    "                if not isinstance(batch_results, list):\n",
    "                    raise ValueError(f\"Model output was not a list (array). Found type: {type(batch_results)}\")\n",
    "\n",
    "                for res in batch_results:\n",
    "                    source_nl = res.get(\"Source_NL\")\n",
    "                    original_item = original_map.get(source_nl)\n",
    "\n",
    "                    if source_nl and original_item:\n",
    "                        all_lifted_results.append({\n",
    "                            \"Source_NL\": source_nl,\n",
    "                            \"Lifted_NL\": res.get(\"Lifted_NL\", \"ERROR: Lifted NL missing\"),\n",
    "                            \"section_id\": original_item.get('section_id', 'N/A')\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"     Critical Parsing/Processing Error: {e}\")\n",
    "                batch_processed_successfully = False # Mark batch as failed during processing\n",
    "\n",
    "        # Log failed items if the API call or processing failed\n",
    "        if not batch_processed_successfully:\n",
    "            for req in batch:\n",
    "                if req['Source_NL'] not in [r.get('Source_NL') for r in all_lifted_results]:\n",
    "                    all_lifted_results.append({\"Source_NL\": req['Source_NL'], \"Error\": \"Batch API/Processing Failed\", \"Lifted_NL\": \"ERROR\"})\n",
    "\n",
    "\n",
    "        # --- RATE LIMITING: Sleep for 60 seconds between batches ---\n",
    "        if i + BATCH_SIZE < len(selected_requirements):\n",
    "            print(f\" Sleeping for 60 seconds (Completed {num_requests} requests)...\")\n",
    "            time.sleep(60)\n",
    "            \n",
    "    with open(LIFTED_NL_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_lifted_results, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"  Intermediate Lifted NL results saved to {LIFTED_NL_PATH}\")\n",
    "    \n",
    "    return [r for r in all_lifted_results if 'ERROR' not in r['Lifted_NL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "723d25c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Running Step 2: Lifting (NL -> Lifted NL) ---\n",
      "\n",
      "--- Step 2: NL to Lifted NL (Lifting) using gemini-2.5-pro ---\n",
      "Waiting 60 seconds to ensure quota reset from previous API call (Step 1)...\n",
      "   Lifting Batch 1 (50 items)...\n",
      " Sleeping for 60 seconds (Completed 1 requests)...\n",
      "   Lifting Batch 2 (43 items)...\n",
      "  Intermediate Lifted NL results saved to srs_lifted_nl.json\n"
     ]
    }
   ],
   "source": [
    "# This step automatically waits 60 seconds to clear the Step 1 quota if necessary.\n",
    "print(\"\\n--- 3. Running Step 2: Lifting (NL -> Lifted NL) ---\")\n",
    "lifted_requirements = step_2_perform_lifting(selected_requirements, MODEL_INSTANCE)\n",
    "\n",
    "# You can now inspect 'srs_lifted_nl.json' or the 'lifted_requirements' list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89a33415",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_SPEC_SCHEMA_BATCH = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"Lifted_NL\": {\"type\": \"string\", \"description\": \"The Lifted NL input.\"},\n",
    "            \"LABEL\": {\"type\": \"string\", \"description\": \"The specification label (e.g., VERIFY_PLUMBER_OK).\"},\n",
    "            \"Precondition\": {\"type\": \"string\", \"description\": \"Logical constraints that must hold before execution.\"},\n",
    "            \"Function\": {\"type\": \"string\", \"description\": \"Function signature (name, parameters, return type, HTTP code).\"},\n",
    "            \"Postcondition\": {\"type\": \"string\", \"description\": \"Logical constraints on the global state after execution, using primed globals (U').\"}\n",
    "        },\n",
    "        \"required\": [\"Lifted_NL\", \"LABEL\", \"Precondition\", \"Function\", \"Postcondition\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "def step_3_perform_translation(lifted_requirements: List[Dict], model_instance: genai.GenerativeModel) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Step 3: Lifted NL to Formal Specification Translation.\n",
    "    Processes lifted requirements in batches for translation.\n",
    "    \"\"\"\n",
    "    final_specs = []\n",
    "    num_requests = 0\n",
    "    \n",
    "    print(f\"\\n--- Step 3: Lifted NL to Formal Specification Translation using {MODEL_ID} ---\")\n",
    "\n",
    "    # --- UPDATED PROMPT: Includes detailed instructions and the desired output structure ---\n",
    "    TRANSLATION_PROMPT = f\"\"\"\n",
    "    You are an expert Formal Specification Translator. Your task is to convert a list of structured 'Lifted NL' statements into formal specifications using predicate logic.\n",
    "\n",
    "    The formal specification must always follow these components: LABEL, Precondition, Function, and Postcondition.\n",
    "\n",
    "    CONTEXT: U is the set of users. m is a manager ID, p is a plumber ID.\n",
    "    - Precondition: Must type-check to Bool.\n",
    "    - Function: Name(param: type) â†’ return [HTTP].\n",
    "    - Postcondition: Uses primed globals (U') to describe the after-state.\n",
    "\n",
    "    You MUST output a single JSON array strictly adhering to this structure:\n",
    "    {json.dumps(FINAL_SPEC_SCHEMA_BATCH, indent=2)}\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- FEW-SHOT EXAMPLE DATA ---\n",
    "    # Define the few-shot example that adheres to the new schema\n",
    "    few_shot_lifted = \"always (manager attempts to verify plumber p AND p's status is unverified) implies (p's status becomes active)\"\n",
    "    few_shot_formal = json.dumps({\n",
    "        \"Lifted_NL\": few_shot_lifted,\n",
    "        \"LABEL\": \"VERIFY_PLUMBER_OK\",\n",
    "        \"Precondition\": \"m âˆˆ dom(U) âˆ§ U[m].role = 'manager' âˆ§ p âˆˆ dom(U) âˆ§ U[p].role = 'plumber' âˆ§ U[p].status = 'unverified'\",\n",
    "        \"Function\": \"verify_plumber(managerID: m, plumberID: p) â†’ 200 OK\",\n",
    "        \"Postcondition\": \"U' = U with U'[p].status = 'active'\"\n",
    "    })\n",
    "    \n",
    "    for i in range(0, len(lifted_requirements), BATCH_SIZE):\n",
    "        batch = lifted_requirements[i:i + BATCH_SIZE]\n",
    "        batch_lifted_nl = [req['Lifted_NL'] for req in batch]\n",
    "        \n",
    "        print(f\"   Translating Batch {num_requests + 1} ({len(batch)} items)...\")\n",
    "\n",
    "        # Few-shot history and current batch query (contents list construction remains the same)\n",
    "        contents = [\n",
    "    # FIX: Explicitly dump the schema dictionary to a string\n",
    "    {\"role\": \"user\", \"parts\": [{\"text\": json.dumps(FINAL_SPEC_SCHEMA_BATCH)}]}, \n",
    "    \n",
    "    {\"role\": \"user\", \"parts\": [{\"text\": few_shot_lifted}]},\n",
    "    {\"role\": \"model\", \"parts\": [{\"text\": few_shot_formal}]},\n",
    "    {\"role\": \"user\", \"parts\": [{\"text\": \"Translate the following Lifted NL sentences:\\n\" + \"\\n\".join(f\"- {s}\" for s in batch_lifted_nl)}]}\n",
    "]\n",
    "        # --- NEW RETRY LOOP FOR API CALL ---\n",
    "        batch_processed_successfully = False\n",
    "        \n",
    "        for attempt in range(1, MAX_API_RETRIES + 1):\n",
    "            try:\n",
    "                response = model_instance.generate_content(contents=contents)\n",
    "                num_requests += 1\n",
    "                batch_processed_successfully = True\n",
    "                break \n",
    "\n",
    "            except Exception as e:\n",
    "                error_message = str(e)\n",
    "                \n",
    "                if \"429\" in error_message and attempt < MAX_API_RETRIES:\n",
    "                    # FIX: INCREASE SLEEP DURATION FOR FREE TIER RELIABILITY\n",
    "                    print(f\"Rate Limit Hit on Attempt {attempt}. Sleeping for 75 seconds before retrying...\")\n",
    "                    time.sleep(75) \n",
    "                else:\n",
    "                    # Log the final error if retries are exhausted or it's not a 429 error\n",
    "                    print(f\"Final Error during Translation Batch {num_requests}: {error_message}\")\n",
    "                    break\n",
    "        # --- END RETRY LOOP ---\n",
    "\n",
    "        # Process results ONLY if the API call was successful\n",
    "        if batch_processed_successfully:\n",
    "            try:\n",
    "                raw_text = response.text.strip()\n",
    "                if raw_text.startswith(\"```\"):\n",
    "                    raw_text = raw_text.strip(\"```json\").strip(\"```\").strip()\n",
    "\n",
    "                batch_formal_specs = json.loads(raw_text)\n",
    "                \n",
    "                # Combine results\n",
    "                for j, formal_spec in enumerate(batch_formal_specs):\n",
    "                    final_specs.append({\n",
    "                        \"Source_NL\": batch[j]['Source_NL'],\n",
    "                        \"Lifted_NL\": formal_spec['Lifted_NL'],\n",
    "                        \"Formal_Spec\": {\n",
    "                            \"LABEL\": formal_spec['LABEL'],\n",
    "                            \"Precondition\": formal_spec['Precondition'],\n",
    "                            \"Function\": formal_spec['Function'],\n",
    "                            \"Postcondition\": formal_spec['Postcondition']\n",
    "                        }\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"     Critical Parsing/Processing Error: {e}\")\n",
    "                for req in batch:\n",
    "                    final_specs.append({\"Source_NL\": req['Source_NL'], \"Lifted_NL\": req['Lifted_NL'], \"Error\": str(e)})\n",
    "\n",
    "        # --- RATE LIMITING: Sleep for 60 seconds between batches (Kept as 60s, but now the retry loop handles the critical delay) ---\n",
    "        if i + BATCH_SIZE < len(lifted_requirements):\n",
    "            print(f\"     ðŸ’¤ Sleeping for 60 seconds (Completed {num_requests} requests, {len(final_specs)} items)...\")\n",
    "            time.sleep(60)\n",
    "\n",
    "    with open(FINAL_SPECS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(final_specs, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"  Final formal specifications saved to {FINAL_SPECS_PATH}\")\n",
    "    \n",
    "    return final_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7af007a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. Running Step 3: Formal Translation ---\n",
      "\n",
      "--- Step 3: Lifted NL to Formal Specification Translation using gemini-2.5-pro ---\n",
      "   Translating Batch 1 (27 items)...\n",
      "  Final formal specifications saved to formal_specifications.json\n",
      "\n",
      "  Final specifications saved to formal_specifications.json.\n"
     ]
    }
   ],
   "source": [
    "# This step automatically waits 60 seconds to clear the Step 2 quota if necessary.\n",
    "print(\"\\n--- 4. Running Step 3: Formal Translation ---\")\n",
    "final_specifications = step_3_perform_translation(lifted_requirements, MODEL_INSTANCE)\n",
    "\n",
    "print(f\"\\n  Final specifications saved to {FINAL_SPECS_PATH}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
